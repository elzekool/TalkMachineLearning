{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes to classify text\n",
    "In this example we will use the Enron-Spam dataset (http://www2.aueb.gr/users/ion/data/enron-spam/) to make a simple Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the datafiles\n",
    "Here we will read in the datafiles. For it to work please first run `download.sh` in the `spam-data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NEWLINE = '\\n'\n",
    "SKIP_FILES = {'cmds'}\n",
    "\n",
    "def read_files(path):\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        for path in dir_names:\n",
    "            read_files(os.path.join(root, path))\n",
    "        for file_name in file_names:\n",
    "            if file_name not in SKIP_FILES:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    past_header, lines = False, []\n",
    "                    f = open(file_path, encoding=\"latin-1\")\n",
    "                    for line in f:\n",
    "                        if past_header:\n",
    "                            lines.append(line)\n",
    "                        elif line == NEWLINE:\n",
    "                            past_header = True\n",
    "                    f.close()\n",
    "                    content = NEWLINE.join(lines)\n",
    "                    yield file_path, content\n",
    "                    \n",
    "\n",
    "\n",
    "def build_data_frame(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for file_name, text in read_files(path):\n",
    "        rows.append({'text': text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "\n",
    "    data_frame = pd.DataFrame(rows, index=index)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "HAM = 'ham'\n",
    "SPAM = 'spam'\n",
    "\n",
    "SOURCES = [\n",
    "    ('./spam-data/beck-s',      HAM),\n",
    "    ('./spam-data/farmer-d',    HAM),\n",
    "    ('./spam-data/kaminski-v',  HAM),\n",
    "    ('./spam-data/kitchen-l',   HAM),\n",
    "    ('./spam-data/lokay-m',     HAM),\n",
    "    ('./spam-data/williams-w3', HAM),\n",
    "    ('./spam-data/BG',          SPAM),\n",
    "    ('./spam-data/GP',          SPAM),\n",
    "    ('./spam-data/SH',          SPAM)\n",
    "]\n",
    "\n",
    "data = pd.DataFrame({'text': [], 'class': []})\n",
    "\n",
    "for path, classification in SOURCES:\n",
    "    data = data.append(build_data_frame(path, classification))\n",
    "\n",
    "data = data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "Below you can see that their is an array generated with the class (ham/spam) and the text contained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./spam-data/GP/part1/msg836.eml</th>\n",
       "      <td>spam</td>\n",
       "      <td>&lt;html&gt;&lt;body&gt;&lt;a href=\"\"&gt;\\n\\nNo doctor visit nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./spam-data/lokay-m/articles/69</th>\n",
       "      <td>ham</td>\n",
       "      <td>Note:  I'm sure you have this on your radar sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./spam-data/SH/HP/prodmsg.2.446410.2005717</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi,\\n\\nI have been using your site for a long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./spam-data/GP/part9/msg13294.eml</th>\n",
       "      <td>spam</td>\n",
       "      <td>&lt;HTML&gt;&lt;HEAD&gt;&lt;META HTTP-EQUIV=3D\"Content-Type\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./spam-data/kaminski-v/poland/4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Szanowny Panie Kaminski!!!\\n\\n\\n\\nBardzo dziek...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           class  \\\n",
       "./spam-data/GP/part1/msg836.eml             spam   \n",
       "./spam-data/lokay-m/articles/69              ham   \n",
       "./spam-data/SH/HP/prodmsg.2.446410.2005717  spam   \n",
       "./spam-data/GP/part9/msg13294.eml           spam   \n",
       "./spam-data/kaminski-v/poland/4              ham   \n",
       "\n",
       "                                                                                         text  \n",
       "./spam-data/GP/part1/msg836.eml             <html><body><a href=\"\">\\n\\nNo doctor visit nee...  \n",
       "./spam-data/lokay-m/articles/69             Note:  I'm sure you have this on your radar sc...  \n",
       "./spam-data/SH/HP/prodmsg.2.446410.2005717  Hi,\\n\\nI have been using your site for a long ...  \n",
       "./spam-data/GP/part9/msg13294.eml           <HTML><HEAD><META HTTP-EQUIV=3D\"Content-Type\" ...  \n",
       "./spam-data/kaminski-v/poland/4             Szanowny Panie Kaminski!!!\\n\\n\\n\\nBardzo dziek...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize\n",
    "The model cannot work with text data. So we need to create a numeric array for it. For this we can use CountVectorizer. It create an column for each word and than set the count for every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(data['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier\n",
    "Train the classifier with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "examples = ['Free Viagra call today!', \"I'm going to learn something about Machine learning\"]\n",
    "example_counts = count_vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
